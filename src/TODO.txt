
5. Rodzaje tokenizacji:
- zmienic rozkład SettingsTokens - przenieść skipy
- sprawdzic czy czegos jeszcze nie trzeba naprawic
- zmienic skipStatmentArgs na skipIfArgs
- wyłączając po kolei tokeny sprawdzić czy wszystko działa dobrze
- tokeny FUNCTION_USE i CONSTRUCTOR_USE scalić w jeden (można oszukać system zmieniając wielkość liter)
- wykrywanie konstruktorów (function_def już ich nie wykrywa)


6. Testy
- nauczyć się dokładnie jak działa algorytm RKR-GST i opisać sposób jego działania w dokumentacji
- napisać testy:
    + normalizacji kodu
    + tokenizacji:
        - scalic kilka plikow z roznych zrodel w jedne plik z kilkoma tysiacami linii kodu
        - umiescic ten plik w projekcie
        - przygotowac test tokenizacji
        - wykorzystać token UNKNOWN
    + wykrywania plagiatu


7. Eksperymenty
- przetestować program na dużej liczbie podobnych projektów (spytać prowadzącego, poszukać na internecie, poszukać w innych pracach o podobnej tematyce)
- czas wykonania algorytmu zmierzyć za pomocą jakiejś funkcji


8. Rozbudowa:
- help - opisac m.in. w oknach - co oznaczają poszczególne kolumny tabel; w ustawieniach tokenow - co oznaczają poszczególne tokeny
- zmodyfikować algorytm RKR-GST lub zaimplementować inne algorytmy i porównać czas ich wykonania (praw. par trzeba będzie liczyć ręcznie)
- zrobić metodę 1 do 1
- CompareFiles - wyświetlić długość najdłuższego znalezionego podobnego fragmentu
- branie pod uwagę procentowego podobieństwa fragmentów (niepodobny kod na początku i końcu fragmentu jest pomijany) + zaimplementować ustawienia
- wyświetlanie tylko par plików z minimalnym procentem podobieństwa

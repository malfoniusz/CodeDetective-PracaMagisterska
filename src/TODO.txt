
- poprawic: konsola - pomoc to_string((_Longlong)(przedmiot[i].numer + 1)) + "" + to_string((_Longlong)(przedmiot[i].rozmiar)) + to_string( (_Longlong)(przedmiot[i].wartosc)) + "";
- refaktoryzacja - czytelny kod, tak żeby wiadomo było co każdy if dokładnie robi
- przy usuwaniu komentarzy przekazac buffer?
- przeslac literature prowadzacemu
- napiszac czesc dokumentacji odnosnie tokenizacji i porownywania tokenow; przeslac prowadzacemu
- rownolegle pisac dokumentacje (tylko pojedyncze zdania przyporzadkowane do danych rozdzialow)

3. Tokenizacja pliku:
- spis tokenów:
    + class Foo - CLASS,
    + void funkcja() - FUNCTION_DEF
    + void funkcja(int a, String b) - FUNCTION_DEF, ARG, ARG
    + funkcja() - FUNCTION_USE
    + System.out.println() - FUNCTION_USE
    + System.out.println("hejka") - FUNCTION_USE, ARG
    + public Konstruktor() - CONSTRUCTOR
    + int, long, double - NUMBER
    + bool - BOOL
    + liczba++ - ASSIGN
    + int i = 0 - NUMBER, ASSIGN
    + string, char - TEXT
    + int* wsk, int *wsk - POINTER
    + new, delete - POINTER_MEM
    + MyClass myClass = new MyClass() - VAR, ASSIGN
    + if, switch - CONDITION
    + for, while, do while - LOOP
    + try, catch - EXCEPTION
    + ignorowanie const
    + if, while, do while - zrobić tylko token, że wystąpiło (pominąć gdzie się zaczyna i kończy)
    + pusta linia lub samo { lub samo } - EMPTY
    + static - STATIC
    + final - FINAL
    + extends, implements
- sprawdzić instrukcje w c++ pod kątem czyszczenia kodu i tokenizacji
- przetestowac tokenizacje dla pojedynczych plikow od różnych osób (wyświetlić i sprawdzić poprawność tokenizacji)


4. Algorytm:
- opcje - wybór minimalnej długości łańcuchów
- algorytm porównujący:
    + zasada działania:
        - z pary plików otrzymujemy dwa gigantyczne ciągi tokenów
        - szukamy takich samych fragmentów tokenów pomiędzy obydwoma ciągami, np. Rabin–Karp algorithm - porównać mniejszy string z większym, Rabin fingerprint, Dynamic pattern matching and hashing to B buckets
        - przeszukujemy gigantyczne ciągi i osobno zliczamy liczbę podobnych linii kodu (puste linii lub zawierające tylko nawias klamrowy, nie zaliczać do podobnych linii)
    + bierze pod uwagę minimalną długość fragmentu
    + raz znalezione identyczne tokeny, nie mogą być użyte do dalszych porównań
    + bierze pod uwagę procentowe podobieństwo fragmentów (niepodobny kod na początku i końcu fragmentu jest pomijany)
    + zwraca dane (numery linii z podobnymi fragmentami kodów)
- (w przypadku zbyt dużej liczby fałszywych wyników):
    + sprecyzować tokeny: NUMBER - NUMBER_WHOLE, NUMBER_DECIMAL - INT, LONG, FLOAT, DOUBLE
    + sprawdzać argumenty w definiowanych i wywoływanych funkcjach i klasach - sprawdzać również kolejność argumentów
    + sprawdzać argumenty w warunkach, np. if (i < 10), while (x == 0)
- opcje(2):
    + wybór procentu podobieństwa łańcuchów
    + wyświetlanie tylko par plików z minimalnym procentem podobieństwa
- help - opis wszystkiego m.in. kolumn tabel


X. Dodatkowe pomysły:
- zmodyfikowac algorytm karpa-rabina (zeby bylo cos zrobionego wlasnego w tej pracy)
- dodatkowe sprawdzenie wynikow - dla linii kodu wykrytych jako podobne (tokeny), sprawdzić czy ich kod jest taki sam (jeśli taki sam to bardziej prawdopodobne, że plagiat)
- sprawdzic efektywnosc tokenizacji dla precyzyjnych tokenow: token LICZBA rozbić na INT, LONG, SHORT
- wykrywanie podobienstwa na roznych poziomach:
	+ 1 do 1 - nie ma znaczenia minimalna liczba kolejno podobnych linii kodu
	+ po wyczyszczeniu pliku 1 do 1 - nie ma znaczenia minimalna... 

- wyświetlenie paska postępu i przeminiętego czasu
- statystyki (czas wykonania programu, liczba identycznych tokenów, inne)
- usuniecie niebezpiecznych znaków przed tokenizacja (twarda spacja, nieznane znaki unicode)
- poprawic: usuwanie komentarzy - int liczba; /* 
